/*
 * LSST Data Management System
 *
 * This product includes software developed by the
 * LSST Project (http://www.lsst.org/).
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the LSST License Statement and
 * the GNU General Public License along with this program.  If not,
 * see <http://www.lsstcorp.org/LegalNotices/>.
 */

// Class header
#include "replica/apps/FileExportApp.h"

// System headersË™
#include <algorithm>
#include <cctype>
#include <fstream>
#include <streambuf>
#include <iostream>
#include <limits>
#include <stdexcept>

// Qserv headers
#include "http/Auth.h"
#include "replica/export/ExportClient.h"
#include "util/File.h"
#include "util/TimeUtils.h"

using namespace std;
using namespace nlohmann;

namespace {

string const description =
        "This is an  application which acts as a client for the "
        " Replication system's table data exporting server.";

bool const injectDatabaseOptions = false;
bool const boostProtobufVersionCheck = true;
bool const enableServiceProvider = false;

string parse(string const& context, json const& jsonObj, string const& key) {
    if ((0 == jsonObj.count(key) or not jsonObj[key].is_string())) {
        throw invalid_argument(context + "No key for <" + key +
                               "> found in the current element of the JSON array"
                               " or its value is not a string");
    }
    return jsonObj[key];
}

template <typename T>
T parse(string const& context, json const& jsonObj, string const& key, T minValue) {
    if ((0 == jsonObj.count(key) or not jsonObj[key].is_number())) {
        throw invalid_argument(context + "No key for <" + key +
                               "> found in the current element of the JSON array"
                               " or its value is not a number");
    }
    uint64_t const num = jsonObj[key];
    if (num < minValue or num > numeric_limits<T>::max()) {
        throw invalid_argument(context + "Failed to parse JSON object, a value " + to_string(num) + " of <" +
                               key + "> is not in a range of " + to_string(minValue) + "-" +
                               to_string(numeric_limits<T>::max()) + ".");
    }
    return (T)num;
}

}  // namespace

namespace lsst::qserv::replica {

list<FileExportApp::FileExportSpec> FileExportApp::parseFileList(json const& jsonObj) {
    string const context = "FileExportApp::" + string(__func__) + "  ";

    list<FileExportApp::FileExportSpec> files;

    if (not jsonObj.is_array()) {
        throw invalid_argument(context +
                               "The input parameter doesn't represent a JSON array of file"
                               " specifications.");
    }

    for (auto&& fileSpecJson : jsonObj) {
        if (not fileSpecJson.is_object()) {
            throw invalid_argument(context +
                                   "The next element in the JSON array doesn't represent a JSON object"
                                   " with a file specification.");
        }
        FileExportApp::FileExportSpec file;

        file.workerHost = parse(context, fileSpecJson, "worker-host");
        file.workerPort = parse<uint16_t>(context, fileSpecJson, "worker-port", 1);
        file.databaseName = parse(context, fileSpecJson, "database");
        file.tableName = parse(context, fileSpecJson, "table");
        file.chunk = parse<unsigned int>(context, fileSpecJson, "chunk", 0);
        file.overlap = parse<unsigned int>(context, fileSpecJson, "overlap", 0);
        file.outFileName = parse(context, fileSpecJson, "path");

        files.push_back(file);
    }
    return files;
}

FileExportApp::Ptr FileExportApp::create(int argc, char* argv[]) {
    return Ptr(new FileExportApp(argc, argv));
}

FileExportApp::FileExportApp(int argc, char* argv[])
        : Application(argc, argv, ::description, ::injectDatabaseOptions, ::boostProtobufVersionCheck,
                      ::enableServiceProvider) {
    // Configure the command line parser

    parser().commands("command", {"FILE", "FILE-LIST"}, _command)
            .option("column-separator",
                    "The column separator in the output files. Allowed values: COMMA, TAB.",
                    _columnSeparatorStr)
            .flag("verbose", "Print various stats upon a completion of the export.", _verbose);

    parser().command("FILE")
            .description(
                    "The single file export option. A source of the export and a path to"
                    " an output file are specified via a group of mandatory parameters.")
            .required("worker-host", "The name of a worker host the Export service is run.", _file.workerHost)
            .required("worker-port", "The port number of the worker's Export service.", _file.workerPort)
            .required("database", "The name of a database which has the desired table.", _file.databaseName)
            .required("table", "The name of a table to be exported.", _file.tableName)
            .required("chunk",
                      "The chunk number. A value of this parameter is ignored for non-partitioned tables.",
                      _file.chunk)
            .required("overlap",
                      "The flag which is set for the partitioned tables to indicate if a table"
                      " 'overlap' is requested.",
                      _file.overlap)
            .required("infile", "A path for a local output file to be created.", _file.outFileName);

    parser().command("FILE-LIST")
            .description(
                    "The batch export option. A list of tables to be exported will be read from"
                    " a file. The content of the file is required to be a serialized JSON array"
                    " of objects. Each object specifies a source of the tab;e export request and"
                    " the name name of a file to write the table data into. The general schema of the JSON "
                    "object is:"
                    " [{\"worker-host\":<string>,\"worker-port\":<number>,\"database\":<string>,"
                    "\"table\":<string>,\"chunk\":<number>,\"overlap\":{0|1},\"path\":<string>},...]."
                    " Where values for the keys \"chunk\" and \"overlap\" are ignored"
                    " for the non-partitioned tables. The tables will be exported sequentially.")
            .required("file-list",
                      "The name of a file with export specifications. If the file name is set to '-'"
                      " then the specifications will be read from the standard input stream",
                      _fileListName);
}

int FileExportApp::runImpl() {
    string const context = "FileExportApp::" + string(__func__) + "  ";

    list<FileExportSpec> files;
    if (_command == "FILE") {
        files.push_back(_file);
    } else if (_command == "FILE-LIST") {
        files = _readFileList();
    } else {
        throw invalid_argument(context + "Unsupported loading method " + _command);
    }
    for (auto&& file : files) {
        _export(file);
    }
    return 0;
}

list<FileExportApp::FileExportSpec> FileExportApp::_readFileList() const {
    string const context = "FileExportApp::" + string(__func__) + "  ";

    ifstream file(_fileListName);
    if (not file.good()) {
        throw invalid_argument(context + "Failed to open file: " + _fileListName);
    }
    string str;
    try {
        str = string(istreambuf_iterator<char>(file), istreambuf_iterator<char>());
    } catch (exception const& ex) {
        throw invalid_argument(context + "Failed to read file: " + _fileListName +
                               ", exception: " + string(ex.what()));
    }
    json jsonObj;
    try {
        jsonObj = json::parse(str);
    } catch (exception const& ex) {
        throw invalid_argument(context + "Failed to parse the content of file: " + _fileListName +
                               " into a JSON object, exception: " + string(ex.what()));
    }
    return parseFileList(jsonObj);
}

void FileExportApp::_export(FileExportSpec const& file) const {
    string const context = "FileExportApp::" + string(__func__) + "  ";

    // Export the table into the file
    //
    // TODO: consider doing this asynchronously in a separate thread while
    // limiting the maximum duration of the operation by a timeout (BOOST ASIO
    // timer launched in a separate thread). A duration of the timeout could be
    // set via an optional parameter to the application.

    ExportClient::ColumnSeparator columnSeparator;
    if ("COMMA" == _columnSeparatorStr) {
        columnSeparator = ExportClient::ColumnSeparator::COMMA;
    } else if ("TAB" == _columnSeparatorStr) {
        columnSeparator = ExportClient::ColumnSeparator::TAB;
    } else {
        throw invalid_argument(context + "unsupported value of the column separator: '" +
                               _columnSeparatorStr + "'");
    }
    uint64_t const startedMs = util::TimeUtils::now();
    auto const ptr = ExportClient::connect(file.workerHost, file.workerPort, file.databaseName,
                                           file.tableName, file.chunk, file.overlap, file.outFileName,
                                           columnSeparator, httpAuthContext().authKey);
    ptr->receive();
    uint64_t const finishedMs = util::TimeUtils::now();

    if (_verbose) {
        uint64_t const elapsedMs = max(1UL, finishedMs - startedMs);
        double const elapsedSec = elapsedMs / 1000;
        double const rowsPerSec = ptr->totalNumRows() / elapsedSec;
        double const megaBytesPerSec = ptr->sizeBytes() / 1000000 / elapsedSec;
        cout << "Exporting service location: " << file.workerHost << ":" << file.workerPort << "\n"
             << "           Source database: " << file.databaseName << "\n"
             << "              Source table: " << file.tableName << "\n"
             << "                     Chunk: " << file.chunk << "\n"
             << "          Is chunk overlap: " << bool2str(file.overlap) << "\n"
             << "          Output file name: " << file.outFileName << "\n"
             << "               Start  time: "
             << util::TimeUtils::toDateTimeString(chrono::milliseconds(startedMs)) << "\n"
             << "               Finish time: "
             << util::TimeUtils::toDateTimeString(chrono::milliseconds(finishedMs)) << "\n"
             << "              Elapsed time: " << elapsedSec << " sec\n"
             << "            Rows  received: " << ptr->totalNumRows() << "\n"
             << "            Bytes received: " << ptr->sizeBytes() << "\n"
             << "                  Rows/sec: " << rowsPerSec << "\n"
             << "                 MByte/sec: " << megaBytesPerSec << "\n"
             << endl;
    }
}

}  // namespace lsst::qserv::replica
